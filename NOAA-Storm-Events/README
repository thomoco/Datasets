Dataset source data location:
http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/

Preparing dataset:
1. Download one or more files from the dataset location, as CSV
2. Concatenate the datasets into a single file:
  $ cat StormEvents* > StormEvents-all.csv

Preparing Elasticsearch:
1. Confirm Elasticsearch and Logstash are installed
2. Confirm Elasticsearch is running, on the sample case on localhost:9200
3. Files are written with a Shield user of "es_admin" created with readwrite
   access
4. Create the mapping
  $ ./create-mapping.sh

Ingest the data:
1. Make sure the logstash-storms.conf file is available
2. Start the logstash-storms.sh file:
  $ ./logstash-storms.sh start

